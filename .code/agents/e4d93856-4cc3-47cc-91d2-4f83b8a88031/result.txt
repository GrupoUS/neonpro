Based on the analysis of `.github/prompts/code-quality-audit.prompt.md`, here is a proposed execution plan for its future refinement. The current prompt is exceptionally detailed and provides a robust foundation for multi-agent workflows. This plan focuses on strategic enhancements to improve its clarity, maintainability, and integration with the broader NeonPro ecosystem.

---

### **Execution Plan: Refinement of Code Quality Audit Prompt**

This plan outlines five core workstreams to guide the evolution of the `code-quality-audit.prompt.md`. The goal is to enhance its effectiveness, ensure long-term alignment with project processes, and improve the developer/agent experience.

#### **Workstream 1: Enhance Prompt Clarity & Maintainability**

This workstream focuses on structural improvements to make the prompt easier to read, parse, and maintain.

*   **Task 1.1: Standardize Configuration Blocks:**
    *   **Action:** Refactor all YAML and shell script blocks to use consistent, machine-parsable formats (e.g., fenced code blocks with language identifiers like `yaml` or `bash`). Remove the use of Markdown blockquotes for code.
    *   **Goal:** Improve programmatic access to the prompt's configuration and reduce ambiguity for both human and AI agents.

*   **Task 1.2: Centralize and Reference Key Definitions:**
    *   **Action:** Create a dedicated `docs/agents/glossary.md` or similar central document for critical terms (`archon_mcp`, `serena_mcp`, `P0`/`P1` priorities, etc.). Replace inline definitions with links to this single source of truth.
    *   **Goal:** Reduce redundancy and ensure that core concepts are defined consistently across the project.

*   **Task 1.3: Implement Prompt Versioning:**
    *   **Action:** Add a version number to the prompt header (e.g., `version: 2.1.0`). Establish a process for incrementing the version when significant changes are made.
    *   **Goal:** Enable audit reports to reference the specific prompt version used, providing traceability and context for historical results.

#### **Workstream 2: Deepen Process & Documentation Integration**

This workstream aims to create a tighter, two-way binding between the prompt and its surrounding assets.

*   **Task 2.1: Create a Documentation Sync Protocol:**
    *   **Action:** Define a checklist or automated script that triggers a review of referenced documents (e.g., `docs/architecture/source-tree.md`) whenever the prompt is updated, and vice-versa.
    *   **Goal:** Prevent procedural drift where the prompt and official documentation become misaligned.

*   **Task 2.2: Abstract Hardcoded Commands:**
    *   **Action:** Replace hardcoded shell commands (`pnpm --filter ...`) with references to `package.json` script names (e.g., `Run '@neonpro/api:lint'`).
    *   **Goal:** Decouple the prompt from the specific implementation of commands, making it more resilient to changes in the build system.

*   **Task 2.3: Consolidate Agent Definitions:**
    *   **Action:** Move the primary definitions of agents (`architect-review`, `security-auditor`, etc.) to the `.claude/agents/` or `docs/agents/` directory. The prompt should reference these canonical definitions rather than defining them internally.
    *   **Goal:** Establish a single source of truth for agent capabilities and roles, reducing duplication.

#### **Workstream 3: Refine Agent Orchestration & Tooling**

This workstream focuses on making the agent interaction more explicit and robust.

*   **Task 3.1: Formalize MCP Agent Contracts:**
    *   **Action:** Create dedicated markdown files (`docs/agents/archon_mcp.md`, `docs/agents/serena_mcp.md`) that formally define the expected inputs, outputs, and functions of the Master Control Program agents.
    *   **Goal:** Provide a clear "API" for how core agents interact with the orchestration layer.

*   **Task 3.2: Define a Schema for Reporting Artifacts:**
    *   **Action:** Create and document a formal JSON Schema for each major report artifact (`security-report.json`, `test-coverage-report.json`).
    *   **Goal:** Ensure consistent, machine-readable output from audits, enabling better downstream processing and historical analysis.

*   **Task 3.3: Expand on "Sequential Thinking" Phase:**
    *   **Action:** Detail the `sequential-thinking` step in `Phase 0` with a concrete checklist of questions for the orchestrator to answer before selecting agents (e.g., "Identify primary change domain: frontend, backend, or database?", "Assess potential for cross-cutting impact.").
    *   **Goal:** Make the initial analysis phase more structured and deterministic.

#### **Workstream 4: Mature Test Coverage & Quality Guidance**

This workstream aims to make the testing guidance more concrete and actionable.

*   **Task 4.1: Externalize the Test Strategy Map:**
    *   **Action:** Move the `path_to_strategy` mapping from `Phase 4.2` into a separate, machine-readable file (e.g., `/.config/testing/test-strategy.json`). The prompt would then reference this file.
    *   **Goal:** Allow the test strategy to be consumed by other tools and evolve independently of the main prompt logic.

*   **Task 4.2: Define "Test Quality" Metrics:**
    *   **Action:** Create a document (`docs/testing/quality-metrics.md`) that defines the "Test quality score" mentioned in the quality gates. Metrics could include assertion count per test, avoidance of generic assertions, use of mocks vs. real instances, and mutation testing scores.
    *   **Goal:** Move from a subjective quality score to an objective, measurable set of criteria.

#### **Workstream 5: Bolster Healthcare & Compliance Directives**

This workstream focuses on strengthening the already-robust compliance features.

*   **Task 5.1: Map Compliance Rules to Specific Code Patterns:**
    *   **Action:** For each regulation (LGPD, CFM), create a mapping document that links specific articles of the regulation to concrete "good" and "bad" code examples relevant to the NeonPro codebase.
    *   **Goal:** Give the `security-auditor` agent a more precise, actionable library of patterns to look for during compliance checks.

*   **Task 5.2: Refine Emergency Access Protocol Validation:**
    *   **Action:** Expand the `Phase 2.4` checklist to include validation of alerting mechanisms (e.g., "Verify that emergency access triggers a P0 alert to the security team") and require documentation checks for the "break-glass" procedures.
    *   **Goal:** Ensure that the audit of emergency protocols is as rigorous as the technical implementation checks.
